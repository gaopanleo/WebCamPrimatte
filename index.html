<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>WebAITest</title>
    <link rel="shortcut icon" href="TemplateData/favicon.ico">
    <link rel="stylesheet" href="TemplateData/style.css">
  </head>
  <body class="dark">
    <div id="unity-container" class="unity-desktop">
      <canvas id="unity-canvas"></canvas>
    </div>
    <div id="loading-cover" style="display:none;">
      <div id="unity-loading-bar">
        <div id="unity-logo"><img src="logo.png"></div>
        <div id="unity-progress-bar-empty" style="display: none;">
          <div id="unity-progress-bar-full"></div>
        </div>
        <div class="spinner"></div>
      </div>
    </div>
    <div id="unity-fullscreen-button" style="display: none;"></div>

    <script>
      const hideFullScreenButton = "";
      const buildUrl = "Build";
      const loaderUrl = buildUrl + "/WebAI.loader.js";
      const config = {
        dataUrl: buildUrl + "/WebAI.data",
        frameworkUrl: buildUrl + "/WebAI.framework.js",
        codeUrl: buildUrl + "/WebAI.wasm",
        streamingAssetsUrl: "StreamingAssets",
        companyName: "DefaultCompany",
        productName: "WebAITest",
        productVersion: "0.1",
      };
      
      const container = document.querySelector("#unity-container");
      const canvas = document.querySelector("#unity-canvas");
      const loadingCover = document.querySelector("#loading-cover");
      const progressBarEmpty = document.querySelector("#unity-progress-bar-empty");
      const progressBarFull = document.querySelector("#unity-progress-bar-full");
      const fullscreenButton = document.querySelector("#unity-fullscreen-button");
      const spinner = document.querySelector('.spinner');

      const canFullscreen = (function() {
        for (const key of [
            'exitFullscreen',
            'webkitExitFullscreen',
            'webkitCancelFullScreen',
            'mozCancelFullScreen',
            'msExitFullscreen',
          ]) {
          if (key in document) {
            return true;
          }
        }
        return false;
      }());

      if (/iPhone|iPad|iPod|Android/i.test(navigator.userAgent)) {
        container.className = "unity-mobile";
        config.devicePixelRatio = 1;
      }
      loadingCover.style.display = "";

      window.unityInstance = null; // Store unityInstance globally

      const script = document.createElement("script");
      script.src = loaderUrl;
      script.onload = () => {
        createUnityInstance(canvas, config, (progress) => {
          spinner.style.display = "none";
          progressBarEmpty.style.display = "";
          progressBarFull.style.width = `${100 * progress}%`;
        }).then((instance) => {
          window.unityInstance = instance; // Store the instance globally
          loadingCover.style.display = "none";
          if (canFullscreen) {
            if (!hideFullScreenButton) {
              fullscreenButton.style.display = "";
            }
            fullscreenButton.onclick = () => {
              window.unityInstance.SetFullscreen(1);
            };
          }
        }).catch((message) => {
          alert(message);
        });
      };
      document.body.appendChild(script);

    </script>

    <script src="tfjs@3.7.0.min.js"></script>
    <script>
      window.InitializeTensorFlow = function () {
        if (typeof tf === 'undefined') {
          console.error("TensorFlow.js load error!");
          return;
        }
       
        console.log("TensorFlow.js initialized");
        const video = document.createElement('video');
        video.id = 'tf-video';
        video.width = 256;
        video.height = 256;
        document.body.appendChild(video);

        const canvas = document.createElement('canvas');
        canvas.id = 'tf-canvas';
        document.body.appendChild(canvas);
        const ctx = canvas.getContext('2d');

        (async () => {
          try {

            const webcam = await tf.data.webcam(video);
            const model = await tf.loadGraphModel('model/model.json');

            //设定初始循环状态
            let [r1i, r2i, r3i, r4i] = [tf.tensor(0.), tf.tensor(0.), tf.tensor(0.), tf.tensor(0.)];

            //设定下采样比
            const downsample_ratio = tf.tensor(0.5);

            // 推理循环
            while (true) {
              await tf.nextFrame();
              const img = await webcam.capture();
              const src = tf.tidy(() => img.expandDims(0).div(255)); // normalize input
              const [fgr, pha, r1o, r2o, r3o, r4o] = await model.executeAsync(
                {src, r1i, r2i, r3i, r4i, downsample_ratio}, // provide inputs
                ['fgr', 'pha', 'r1o', 'r2o', 'r3o', 'r4o']   // select outputs
              );

              //绘制结果
              drawMatte(fgr.clone(), pha.clone(), canvas);
              canvas.style.background = 'rgb(0, 0, 0)';

              //释放旧张量
              tf.dispose([img, src, fgr, pha, r1i, r2i, r3i, r4i]);

              //更新循环状态
              [r1i, r2i, r3i, r4i] = [r1o, r2o, r3o, r4o];
		
            }
          } catch (error) {
            console.error("Runtime error:", error);
          }
        })();
      };

   let lastSentTime = 0;
const sendInterval = 1000/30; // 每 100ms 发送一次数据

async function drawMatte(fgr, pha, canvas) {
    const rgba = tf.tidy(() => {
        const rgb = (fgr !== null) ? 
            fgr.squeeze(0).mul(255).cast('int32') : 
            tf.fill([pha.shape[1], pha.shape[2], 3], 255, 'int32');
        const a = (pha !== null) ? 
            pha.squeeze(0).mul(255).cast('int32') : 
            tf.fill([fgr.shape[1], fgr.shape[2], 1], 255, 'int32');
        return tf.concat([rgb, a], -1);
    });
    fgr && fgr.dispose();
    pha && pha.dispose();
    
    const [height, width] = rgba.shape.slice(0, 2);

    // 将图像数据转换为 ImageData
    const pixelData = new Uint8ClampedArray(await rgba.data());
    const imageData = new ImageData(pixelData, width, height);

    // 渲染到 canvas
    canvas.width = width;
    canvas.height = height;
    const ctx = canvas.getContext('2d');
    ctx.putImageData(imageData, 0, 0);

    // 获取当前时间
    const currentTime = Date.now();

    // 检查是否已经超过了设定的发送间隔时间
    if (currentTime - lastSentTime >= sendInterval) {
        // 转换 canvas 为 Base64 格式
        const base64Data = canvas.toDataURL('image/png');
        
        // 发送数据到 Unity
        SendToUnity(base64Data);
        
        // 更新上次发送时间
        lastSentTime = currentTime;
    }

    rgba.dispose();
}

      function SendToUnity(data) {
        if (window.unityInstance) {  // Access unityInstance globally
          window.unityInstance.SendMessage('TensorFlowManager', 'OnImageDataReceived', data);
        } else {
          console.error("Unity instance is not available.");
        }
      }
    </script>
  </body>
</html>
